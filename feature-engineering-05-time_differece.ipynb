{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd043b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76021d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(data):\n",
    "    \n",
    "    df = data[['shop_id', 'item_brand_id', 'item_id', 'item_category_1','item_pv_level','item_sales_level','item_collected_level',\n",
    "              'item_price_level','context_page_id', 'day', 'hour', 'maphour', 'context_timestamp', 'user_id', 'instance_id']]\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "    cols = df.columns.tolist()\n",
    "    keys = ['instance_id', 'day']\n",
    "    for k in keys:\n",
    "        cols.remove(k)\n",
    "\n",
    "    return df, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c8acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def user_check(df, behaviour):\n",
    "\n",
    "    df.sort_values(['user_id', 'context_timestamp'], inplace=True)\n",
    "\n",
    "    user_day = df.groupby(['user_id', 'day', behaviour]).size().reset_index().rename(columns={0: 'user_id_query_day_{}'.format(behaviour)})\n",
    "    df = pd.merge(df, user_day, how = 'left', on=['user_id', 'day',behaviour])\n",
    "    user_day_hour = df.groupby(['user_id', 'day', 'hour', behaviour]).size().reset_index().rename(columns={0: 'user_id_query_day_hour_{}'.format(behaviour)})\n",
    "    df = pd.merge(df, user_day_hour, how = 'left', on=['user_id', 'day', 'hour',behaviour])\n",
    "    user_day_hour_map = df.groupby(['user_id', 'day', 'maphour', behaviour]).size().reset_index().rename(columns={0: 'user_id_query_day_hour_map_{}'.format(behaviour)})\n",
    "    df = pd.merge(df, user_day_hour_map, how = 'left', on=['user_id', 'day', 'maphour',behaviour])\n",
    "\n",
    "    n = 0\n",
    "    check_time_day = np.ones((len(df),1))\n",
    "    check_time_difference_last = np.ones((len(df),1))\n",
    "    num = {}\n",
    "    timeseries = {}\n",
    "    bd = df.day.min()\n",
    "    for u, i, d in zip(df.user_id, df[behaviour], df.day):\n",
    "        n += 1\n",
    "        try:\n",
    "            num[(u,i)] += 1\n",
    "            # timeseries[(u,i)] = df.min_series_full[n-1] - timeseries[(u,i)]\n",
    "            check_time_difference_last[n-1] = df.context_timestamp[n-1] - timeseries[(u,i)]\n",
    "            timeseries[(u,i)] = df.context_timestamp[n-1]\n",
    "        except:\n",
    "            num[(u,i)] = 0\n",
    "            timeseries[(u,i)] = df.context_timestamp[n-1]\n",
    "            check_time_difference_last[n-1] = -1\n",
    "\n",
    "        check_time_day[n-1] = num[(u,i)]\n",
    "        if d > bd:\n",
    "            num = {}\n",
    "        bd = d\n",
    "    check_time_difference_next = np.ones((len(df),1))\n",
    "    timeseries = {}\n",
    "    for i in range(len(df)): #df.user_id[::-1]:\n",
    "        u = df.user_id[len(df)-i-1]\n",
    "        b = df[behaviour][len(df)-i-1]\n",
    "        try:\n",
    "            check_time_difference_next[len(df)-i-1] = timeseries[(u,b)]- df.context_timestamp[len(df)-i-1]\n",
    "        except:\n",
    "            check_time_difference_next[len(df)-i-1] = -1\n",
    "        timeseries[(u,b)] = df.context_timestamp[len(df)-i-1]\n",
    "\n",
    "    df['check_{}_min_diff_last'.format(behaviour)] = check_time_difference_last\n",
    "    df['check_{}_min_diff_next'.format(behaviour)] = check_time_difference_next\n",
    "\n",
    "    df['check_{}_time_day'.format(behaviour)] = check_time_day\n",
    "    df['check_{}_ratio'.format(behaviour)] = df['check_{}_time_day'.format(behaviour)] / df['user_id_query_day_{}'.format(behaviour)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72111467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始维度: (99085, 33)\n",
      "pre_process: (99085, 15)\n",
      "shop_id starting...\n",
      "item_brand_id starting...\n",
      "item_id starting...\n",
      "item_category_1 starting...\n",
      "item_pv_level starting...\n",
      "item_sales_level starting...\n",
      "item_collected_level starting...\n",
      "item_price_level starting...\n",
      "context_page_id starting...\n",
      "经过处理后,全部训练集最终维度: (99085, 65)\n",
      "经过处理后,7号训练集最终维度: (10184, 64)\n",
      "['instance_id', 'user_id_query_day_shop_id', 'user_id_query_day_hour_shop_id', 'user_id_query_day_hour_map_shop_id', 'check_shop_id_min_diff_last', 'check_shop_id_min_diff_next', 'check_shop_id_time_day', 'check_shop_id_ratio', 'user_id_query_day_item_brand_id', 'user_id_query_day_hour_item_brand_id', 'user_id_query_day_hour_map_item_brand_id', 'check_item_brand_id_min_diff_last', 'check_item_brand_id_min_diff_next', 'check_item_brand_id_time_day', 'check_item_brand_id_ratio', 'user_id_query_day_item_id', 'user_id_query_day_hour_item_id', 'user_id_query_day_hour_map_item_id', 'check_item_id_min_diff_last', 'check_item_id_min_diff_next', 'check_item_id_time_day', 'check_item_id_ratio', 'user_id_query_day_item_category_1', 'user_id_query_day_hour_item_category_1', 'user_id_query_day_hour_map_item_category_1', 'check_item_category_1_min_diff_last', 'check_item_category_1_min_diff_next', 'check_item_category_1_time_day', 'check_item_category_1_ratio', 'user_id_query_day_item_pv_level', 'user_id_query_day_hour_item_pv_level', 'user_id_query_day_hour_map_item_pv_level', 'check_item_pv_level_min_diff_last', 'check_item_pv_level_min_diff_next', 'check_item_pv_level_time_day', 'check_item_pv_level_ratio', 'user_id_query_day_item_sales_level', 'user_id_query_day_hour_item_sales_level', 'user_id_query_day_hour_map_item_sales_level', 'check_item_sales_level_min_diff_last', 'check_item_sales_level_min_diff_next', 'check_item_sales_level_time_day', 'check_item_sales_level_ratio', 'user_id_query_day_item_collected_level', 'user_id_query_day_hour_item_collected_level', 'user_id_query_day_hour_map_item_collected_level', 'check_item_collected_level_min_diff_last', 'check_item_collected_level_min_diff_next', 'check_item_collected_level_time_day', 'check_item_collected_level_ratio', 'user_id_query_day_item_price_level', 'user_id_query_day_hour_item_price_level', 'user_id_query_day_hour_map_item_price_level', 'check_item_price_level_min_diff_last', 'check_item_price_level_min_diff_next', 'check_item_price_level_time_day', 'check_item_price_level_ratio', 'user_id_query_day_context_page_id', 'user_id_query_day_hour_context_page_id', 'user_id_query_day_hour_map_context_page_id', 'check_context_page_id_min_diff_last', 'check_context_page_id_min_diff_next', 'check_context_page_id_time_day', 'check_context_page_id_ratio']\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    path = '/Users/apple/Desktop/data/'\n",
    "    \n",
    "    train = pd.read_csv(path+'train_all.csv')\n",
    "    test = pd.read_csv(path+'test_all.csv')\n",
    "\n",
    "    # train = pd.read_csv(path+'train_day7.csv')\n",
    "    # test = pd.read_csv(path+'test_day7.csv')\n",
    "\n",
    "    data = pd.concat([train, test])\n",
    "    print('初始维度:', data.shape)\n",
    "    \n",
    "    #####################################\n",
    "    data, cols = pre_process(data)\n",
    "    print('pre_process:', data.shape)\n",
    "\n",
    "    for f in ['shop_id', 'item_brand_id', 'item_id', 'item_category_1','item_pv_level','item_sales_level','item_collected_level',\n",
    "              'item_price_level','context_page_id']:\n",
    "        print(f,'starting...')\n",
    "        data = user_check(data, f)\n",
    "    #####################################\n",
    "\n",
    "    data = data.drop(cols, axis=1)\n",
    "\n",
    "    # 得到全部训练集\n",
    "    print('经过处理后,全部训练集最终维度:', data.shape)\n",
    "    data.to_csv(path+'all_05.csv', index=False)\n",
    "\n",
    "    # 得到7号训练集\n",
    "    data = data.loc[data.day==7]\n",
    "    data = data.drop('day', axis=1)\n",
    "    print('经过处理后,7号训练集最终维度:', data.shape)\n",
    "    print(data.columns.tolist())\n",
    "    data.to_csv(path+'day7_05.csv', index=False)\n",
    "    \n",
    "    path = '/Users/apple/Desktop/data/'\n",
    "    # 将列和数据类型存储为 DataFrame\n",
    "    columns_data_types = pd.DataFrame({'Column': data.columns, 'Data Type':data.dtypes})\n",
    "\n",
    "    # 保存为 CSV 文件\n",
    "    columns_data_types.to_csv(path+'columns_data_types5.csv', index=False)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
