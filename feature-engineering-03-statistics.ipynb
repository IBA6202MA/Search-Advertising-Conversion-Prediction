{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理 (pre_process 函数)，从数据中删除不必要的列（instance_id 和 day）返回处理后的数据和要删除的列名列表。\n",
    "def pre_process(data):\n",
    "    \n",
    "    cols = data.columns.tolist()\n",
    "    keys = ['instance_id', 'day']\n",
    "    for k in keys:\n",
    "        cols.remove(k)\n",
    "\n",
    "    return data, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#滚动窗口特征生成 (dorollWin 函数):将context_timestamp转换为字符串类型，并创建基于时间的各种特征，\n",
    "#计算用户在10分钟窗口内的事件数（点击次数）(user_count_10_bf 和 user_count_10_af)，类似的计算应用于用户-商店和用户-商品组合。\n",
    "\n",
    "#将 'context_timestamp' 列的时间戳转换为字符串类型，并创建一个名为 'context_timestamp_str' 的新列，其中包含时间戳的字符串表示\n",
    "#按用户ID分组，并将每个用户的 'context_timestamp_str' 连接成一个由分号分隔的字符串。然后，将这些信息合并回原始数据中，创建一个名为 'user_time_join' 的新列\n",
    "#用户-商店和用户-商品组合进行类似\n",
    "\n",
    "def dorollWin(data):\n",
    "\n",
    "    data['context_timestamp_str'] = data['context_timestamp'].astype(str)\n",
    "    user_time_join = data.groupby('user_id')['context_timestamp_str'].agg(lambda x:';'.join(x)).reset_index()\n",
    "    user_time_join.rename(columns={'context_timestamp_str':'user_time_join'},inplace = True)\n",
    "\n",
    "    data = pd.merge(data,user_time_join,on=['user_id'],how='left')\n",
    "    user_shop_time_join = data.groupby(['user_id','shop_id'])['context_timestamp_str'].agg(lambda x:';'.join(x)).reset_index()\n",
    "    user_shop_time_join.rename(columns={'context_timestamp_str':'user_shop_time_join'},inplace = True)\n",
    "\n",
    "    data = pd.merge(data,user_shop_time_join,on=['user_id','shop_id'],how='left')\n",
    "    user_item_time_join = data.groupby(['user_id','item_id'])['context_timestamp_str'].agg(lambda x:';'.join(x)).reset_index()\n",
    "    user_item_time_join.rename(columns={'context_timestamp_str':'user_item_time_join'},inplace = True)\n",
    "    \n",
    "    data = pd.merge(data,user_item_time_join,on=['user_id','item_id'],how='left')\n",
    "    data['index_']=data.index\n",
    "    del user_time_join,user_shop_time_join,user_item_time_join\n",
    "    \n",
    "    nowtime=data.context_timestamp.values\n",
    "    user_time=data.user_time_join.values\n",
    "    user_shop_time=data.user_shop_time_join.values\n",
    "    user_item_time=data.user_item_time_join.values\n",
    "    \n",
    "    data_len=data.shape[0]\n",
    "    user_time_10_bf=np.zeros(data_len)\n",
    "    user_time_10_af=np.zeros(data_len)\n",
    "    user_shop_time_10_bf=np.zeros(data_len)\n",
    "    user_shop_time_10_af=np.zeros(data_len)\n",
    "    user_item_time_10_bf=np.zeros(data_len)\n",
    "    user_item_time_10_af=np.zeros(data_len)\n",
    "    a=time.time()\n",
    "    for i in range(data_len):\n",
    "        df1=nowtime[i]\n",
    "        df2=user_time[i].split(';')\n",
    "        df2_len=len(df2)\n",
    "        for j in range(df2_len):\n",
    "            if ((int(df2[j])-df1)<600) & ((int(df2[j])-df1)>0):\n",
    "                user_time_10_bf[i]+=1\n",
    "            if ((int(df2[j])-df1)>-600) & ((int(df2[j])-df1)<0):\n",
    "                user_time_10_af[i]+=1\n",
    "        \n",
    "        df3=user_shop_time[i].split(';')\n",
    "        df3_len=len(df3)\n",
    "        for j in range(df3_len):\n",
    "            if ((int(df3[j])-df1)<600) & ((int(df3[j])-df1)>0):\n",
    "                user_shop_time_10_bf[i]+=1\n",
    "            if ((int(df3[j])-df1)>-600) & ((int(df3[j])-df1)<0):\n",
    "                user_shop_time_10_af[i]+=1\n",
    "                \n",
    "        df4=user_item_time[i].split(';')\n",
    "        df4_len=len(df4)\n",
    "        for j in range(df4_len):\n",
    "            if ((int(df4[j])-df1)<600) & ((int(df4[j])-df1)>0):\n",
    "                user_item_time_10_bf[i]+=1\n",
    "            if ((int(df4[j])-df1)>-600) & ((int(df4[j])-df1)<0):\n",
    "                user_item_time_10_af[i]+=1\n",
    "                \n",
    "    print(time.time()-a)\n",
    "    \n",
    "    data['user_count_10_bf']=user_time_10_bf\n",
    "    data['user_count_10_af']=user_time_10_af\n",
    "    data['user_shop_count_10_bf']=user_shop_time_10_bf\n",
    "    data['user_shop_count_10_af']=user_shop_time_10_af\n",
    "    data['user_item_count_10_bf']=user_item_time_10_bf\n",
    "    data['user_item_count_10_af']=user_item_time_10_af\n",
    "\n",
    "    drops = ['context_timestamp_str', 'user_time_join', 'user_shop_time_join',\n",
    "       'user_item_time_join', 'index_']\n",
    "    data = data.drop(drops, axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#大小（size）特征生成 (doSize 函数):计算每个商店在给定日期内唯一的商品数量 (shop_item_unique_day)\n",
    "#计算每个用户在给定日期内的查询次数 (user_id_query_day)\n",
    "#将 'minute' 特征分成不同的时间间隔（10、15、30、45分钟）\n",
    "#计算用户在这些时间间隔内的点击次数 (min10_user_click、min15_user_click、min30_user_click、min45_user_click)\n",
    "def doSize(data):\n",
    "  \n",
    "\n",
    "  #按用户、用户-商店、用户-商品分组并连接时间戳字符串\n",
    "    add = pd.DataFrame(data.groupby([\"shop_id\", \"day\"]).item_id.nunique()).reset_index()\n",
    "    add.columns = [\"shop_id\", \"day\", \"shop_item_unique_day\"]\n",
    "    data = data.merge(add, on=[\"shop_id\", \"day\"], how=\"left\")\n",
    "\n",
    "    user_query_day = data.groupby(['user_id', 'day']).size().reset_index().rename(columns={0: 'user_id_query_day'})\n",
    "    data = pd.merge(data, user_query_day, how='left', on=['user_id', 'day'])\n",
    "    \n",
    "    data['min_10'] = data['minute'] // 10\n",
    "    data['min_15'] = data['minute'] // 15\n",
    "    data['min_30'] = data['minute'] // 30\n",
    "    data['min_45'] = data['minute'] // 45\n",
    "    \n",
    "    # user 不同时间段点击次数，这一步通过循环遍历数据集，在每个数据点处计算用户在10分钟窗口内的事件数（点击次数），包括用户、用户-商店和用户-商品的组合\n",
    "    min10_user_click = data.groupby(['user_id', 'day', 'hour', 'min_10']).size().reset_index().rename(columns={0:'min10_user_click'})\n",
    "    min15_user_click = data.groupby(['user_id', 'day', 'hour', 'min_15']).size().reset_index().rename(columns={0:'min15_user_click'})\n",
    "    min30_user_click = data.groupby(['user_id', 'day', 'hour', 'min_30']).size().reset_index().rename(columns={0:'min30_user_click'})\n",
    "    min45_user_click = data.groupby(['user_id', 'day', 'hour', 'min_45']).size().reset_index().rename(columns={0:'min45_user_click'})\n",
    "\n",
    "    data = pd.merge(data, min10_user_click, 'left', on=['user_id', 'day', 'hour', 'min_10'])\n",
    "    data = pd.merge(data, min15_user_click, 'left', on=['user_id', 'day', 'hour', 'min_15'])\n",
    "    data = pd.merge(data, min30_user_click, 'left', on=['user_id', 'day', 'hour', 'min_30'])\n",
    "    data = pd.merge(data, min45_user_click, 'left', on=['user_id', 'day', 'hour', 'min_45'])\n",
    "    \n",
    "    del data['min_10']\n",
    "    del data['min_15']\n",
    "    del data['min_30']\n",
    "    del data['min_45']\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始维度: (99085, 35)\n",
      "pre_process: (99085, 35)\n",
      "0.544348955154419\n",
      "dorollWin: (99085, 41)\n",
      "doSize: (99085, 47)\n",
      "经过处理后,全部训练集最终维度: (99085, 14)\n",
      "经过处理后,7号数据集最终维度:: (10184, 13)\n",
      "['instance_id', 'user_count_10_bf', 'user_count_10_af', 'user_shop_count_10_bf', 'user_shop_count_10_af', 'user_item_count_10_bf', 'user_item_count_10_af', 'shop_item_unique_day', 'user_id_query_day', 'min10_user_click', 'min15_user_click', 'min30_user_click', 'min45_user_click']\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/apple/Desktop/data/'\n",
    "\n",
    "train = pd.read_csv(path+'train_all.csv')\n",
    "test = pd.read_csv(path+'test_all.csv')\n",
    "\n",
    "data = pd.concat([train, test])\n",
    "print('初始维度:', data.shape)\n",
    "    \n",
    "data, cols = pre_process(data)\n",
    "print('pre_process:', data.shape)\n",
    "    \n",
    "##################################\n",
    "data = dorollWin(data)\n",
    "print('dorollWin:', data.shape)\n",
    "\n",
    "data = doSize(data)\n",
    "print('doSize:', data.shape)\n",
    "##################################\n",
    "    \n",
    "data = data.drop(cols, axis=1)\n",
    "\n",
    "# 得到全部训练集\n",
    "print('经过处理后,全部训练集最终维度:', data.shape)\n",
    "data.to_csv(path+'all_03.csv', index=False)\n",
    "\n",
    "    \n",
    "# 得到7号训练集\n",
    "data = data.loc[data.day == 7]\n",
    "print('经过处理后,7号数据集最终维度::',data.shape)\n",
    "print(data.columns.tolist())\n",
    "data.to_csv(path+'day7_03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
